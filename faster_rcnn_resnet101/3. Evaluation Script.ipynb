{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa082d3-1ce9-4020-a41d-9c72aad71756",
   "metadata": {},
   "source": [
    "# 7144COMP/CW2: Bird Multiple Object Detection Using Faster R-CNN ResNet101 Network \n",
    "## PART III: Model evaluation and deployment\n",
    "\n",
    "### Overview\n",
    "\n",
    "In this notebook, I will evaluate my model through TensorBoard while using the generated metrics to determine model convergence (both validation loss and Intersection over Union (IoU) at both 0.5 and 0.75 are considered). \n",
    "\n",
    "The number of epochs to train the model is set to 1, the reason for this choice was explained in the training notebook. In addition, during the 1st epoch of training, the model converged around the final loss value (smoothed loss value with a weight of 0.8).\n",
    "\n",
    "\n",
    "\n",
    "For the current task, the following steps have been undertaken: \n",
    "\n",
    "- Run the necessary evaluation scripts\n",
    "- Launch TensorBoard displaying both the train and evaluation metrics for the given session. \n",
    "- Provide justification for the number of epochs used for training your object detection model\n",
    "\n",
    "### Next\n",
    "\n",
    "In the next notebook which is an extension to the present, I will:\n",
    "\n",
    "- Freeze my trained model in correct format for model inferencing\n",
    "- Develop a Jupyter Notebook to perform inference on the frozen model using unseen test images\n",
    "- Discuss my results.\n",
    "\n",
    "### Prerequisites\n",
    "This notebook runs locally on the environment *tf-gpu*.\n",
    "- Environment Setup (see Part 0)\n",
    "- Preprocessing (see Part 1)\n",
    "- Training (see Part 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a13b846-f597-4ef3-a11c-a87913e96351",
   "metadata": {},
   "source": [
    "## 1. Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb3cd42c-70f0-4302-8fc2-5d11fed5b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d3796a-cc91-4ebe-913b-df561cd6d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current directory\n",
    "current_dir = os.getcwd()\n",
    "# Model training directory and config pipeline\n",
    "model_dir = os.path.join(current_dir, 'training')\n",
    "pipeline_config_path = 'fasterrcnn_config.config'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8126308-daa1-415b-b44f-c82ecccba07c",
   "metadata": {},
   "source": [
    "## 2. Run the evaluation script\n",
    "\n",
    "```model_main_tf2.py``` (same used for training to create train logs) performs evaluation when some arguments are specified. The last checkpoint is loaded from the ```checkpoint_dir``` directory, to load the last state of the model, and use the model ```pipeline_config_path``` to create en eval folder inside the training folder containing the logs of evaluation. \n",
    "\n",
    "Later on, in the next notebook, we point ```logdir``` to the eval folder to plot eval metrics on TensorBoard.\n",
    "\n",
    "**DetectionBoxes_Precision:**\n",
    "\n",
    "- 'DetectionBoxes_Precision/mAP': mean average precision over classes averaged over IoU thresholds ranging from .5 to .95 with .05 increments.\n",
    "- 'DetectionBoxes_Precision/mAP@.50IOU': mean average precision at 50% IoU\n",
    "- 'DetectionBoxes_Precision/mAP@.75IOU': mean average precision at 75% IoU\n",
    "- 'DetectionBoxes_Precision/mAP (small)': mean average precision for small objects (area < 32^2 pixels).\n",
    "- 'DetectionBoxes_Precision/mAP (medium)': mean average precision for medium sized objects (32^2 pixels < area < 96^2 pixels).\n",
    "- 'DetectionBoxes_Precision/mAP (large)': mean average precision for large objects (96^2 pixels < area < 10000^2 pixels).\n",
    "\n",
    "**DetectionBoxes_Recall**\n",
    "\n",
    "- 'DetectionBoxes_Recall/AR@1': average recall with 1 detection.\n",
    "- 'DetectionBoxes_Recall/AR@10': average recall with 10 detections.\n",
    "- 'DetectionBoxes_Recall/AR@100': average recall with 100 detections.\n",
    "- 'DetectionBoxes_Recall/AR@100 (small)': average recall for small objects with 100.\n",
    "- 'DetectionBoxes_Recall/AR@100 (medium)': average recall for medium objects with 100.\n",
    "- 'DetectionBoxes_Recall/AR@100 (large)': average recall for large objects with 100 detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28878ac9-8a58-4110-8cdd-9db1b2bb6b4c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Execute evaluation script\n",
    "# This will create an **eval** folder inside the training folder\n",
    "!python $current_dir/models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path=$pipeline_config_path \\\n",
    "    --model_dir=$model_dir \\\n",
    "    --checkpoint_dir=$model_dir \\\n",
    "    --run_once=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ebbd6e-3da3-4881-83dc-06f2cb9ddc84",
   "metadata": {},
   "source": [
    "### Next\n",
    "- Launch TensorBoard displaying both the train and evaluation metrics for the given session"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlowGPU",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
