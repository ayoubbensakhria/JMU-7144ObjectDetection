{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d4463c0-f797-4245-9ad7-559712c18db1",
   "metadata": {},
   "source": [
    "# 7144COMP/CW2: Bird Multiple Object Detection Using Faster R-CNN and SSD\n",
    "## PART 2.Training\n",
    "### Overview\n",
    "In this notebook, I will train an object detection model using the pre-processed data from the previous notebook. \n",
    "\n",
    "- Download the object detection models from Tensorflow 2 Detection Model Zoo >> [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md).\n",
    "- The model's hyperparameters and configuration are set in the ```fasterrcnn_config.config``` file. \n",
    "- The model is trained through this notebook using ```model_main_tf2.py``` with the relevent arguments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37b3612-55a0-4cf5-be10-e9ce65245fd4",
   "metadata": {},
   "source": [
    "#### Prerequisites\n",
    "- Environment Setup (see Part 0)\n",
    "- Data preprocessing (see Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0563550b-3c9f-4b45-82c2-c0abfd6e01c1",
   "metadata": {},
   "source": [
    "## 1. Download the model from TensorFlow 2 Detection Model Zoo \n",
    "#### Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac16e330-692f-4f7c-a626-119c1865ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re #<- regular expressions\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179b1929-631f-4b0f-a234-717b6f011e6d",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d8807fd-9e1c-4546-9959-f0b9cac5293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "RANDOM_SEED = 99 #<-ensure the reproduciblity of the training results\n",
    "BATCH_SIZE = 1\n",
    "NUM_STEPS = 21000 # <- for 7 epochs (1 epoch=3000 training steps)\n",
    "NUM_EVAL_STEPS = 1000 #<- execute the eval script (part 3) each 1000 steps\n",
    "\n",
    "# Current directory\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0872c116-1e0b-4dce-ba6e-de309d3d3bb7",
   "metadata": {},
   "source": [
    "#### Download Fine-tuned ```Faster R-CNN ResNet101``` from Tensorflow 2 Detection Model Zoo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a33958-a897-462d-856c-357f1e9d41ed",
   "metadata": {},
   "source": [
    "**Why Faster R-CNN**?\n",
    "\n",
    "Faster R-CNN is an object detection model that improves on Fast R-CNN by utilising a region proposal network (RPN) with the CNN model.\n",
    "\n",
    "Faster R-CNN has impressive detection effects in ordinary scenes ([source](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7582940/)).\n",
    "\n",
    "However, under certain conditions, there can still be unsatisfactory detection performance, such as: the object having problems like occlusion, deformation, or small size ([source](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7582940/)).\n",
    "\n",
    "Our project deals with ordinary scenes, according to the requirements, we should prioritise accuracy over speed, therefore, two-step object detectors like Faster R-CNN may be the most suitable for this task given the limitations in terms of time and computing power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9267bd88-8fb2-40d4-8483-a6c6c267946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Faster R-CNN ResNet101 if it doesn't exist locally\n",
    "if not os.path.isdir('faster_rcnn_resnet101_v1_640x640_coco17_tpu-8'):\n",
    "    !wget http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.tar.gz\n",
    "    # Unzip and remove compressed files\n",
    "    !tar -xf faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.tar.gz\n",
    "    # Cleanup\n",
    "    !rm faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fedcb094-6201-49db-8ba4-b1266936ae86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-11 21:31:32--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.179.240, 2a00:1450:4009:81d::2010\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.179.240|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 386527459 (369M) [application/x-tar]\n",
      "Saving to: ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n",
      "\n",
      "ssd_resnet101_v1_fp 100%[===================>] 368.62M   107MB/s    in 3.5s    \n",
      "\n",
      "2023-01-11 21:31:36 (106 MB/s) - ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [386527459/386527459]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download SSD ResNet101 if it doesn't exist locally\n",
    "if not os.path.isdir('ssd_resnet101_v1_fpn_640x640_coco17_tpu-8'):\n",
    "    !wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
    "    # Unzip and remove compressed files\n",
    "    !tar -xf ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
    "    # Cleanup\n",
    "    !rm ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915eae5c-77c2-4f80-b3fe-d942b5b4a793",
   "metadata": {},
   "source": [
    "#### Load Train, Test, Valid TFRecords, labelmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b17bb00-d083-45a2-936d-3619d031fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Test, Valid TFRecord files\n",
    "train_record_path = os.path.join(current_dir, 'Birds', 'train', 'birds.tfrecord')\n",
    "test_record_path = os.path.join(current_dir, 'Birds', 'test', 'birds.tfrecord')\n",
    "valid_record_path = os.path.join(current_dir, 'Birds', 'valid', 'birds.tfrecord')\n",
    "\n",
    "# Labelmap\n",
    "labelmap_path = os.path.join(current_dir, 'Birds', 'train', 'birds_label_map.pbtxt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f1396c-e1e1-4789-b7a3-add9e25d2356",
   "metadata": {},
   "source": [
    "# 2. Model's Config files, Checkpoints and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc6bd2e2-57d3-4b04-9dc2-9089c662bdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint Dir FasterRCNN: faster_rcnn_resnet101_v1_640x640_coco17_tpu-8/checkpoint/ckpt-0\n",
      "Checkpoint Dir SSD: ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\n"
     ]
    }
   ],
   "source": [
    "# Load the latest Checkpoint if it exists\n",
    "fine_tune_checkpoint_fasterrcnn = 'faster_rcnn_resnet101_v1_640x640_coco17_tpu-8/checkpoint/ckpt-0'\n",
    "fine_tune_checkpoint_ssd = 'ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0'\n",
    "\n",
    "print('Checkpoint Dir FasterRCNN:', fine_tune_checkpoint_fasterrcnn)\n",
    "print('Checkpoint Dir SSD:', fine_tune_checkpoint_ssd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40bfea51-4528-4254-b9b1-438939b08e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-11 21:38:20--  https://raw.githubusercontent.com/ayoubbensakhria/TensorFlowOD/master/7144COMP/training/pipeline.config\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3834 (3.7K) [text/plain]\n",
      "Saving to: ‘pipeline.config’\n",
      "\n",
      "pipeline.config     100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-01-11 21:38:20 (106 MB/s) - ‘pipeline.config’ saved [3834/3834]\n",
      "\n",
      "--2023-01-11 21:38:20--  https://raw.githubusercontent.com/ayoubbensakhria/TensorFlowOD/master/7144COMP/training/ssd_pipeline.config\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4788 (4.7K) [text/plain]\n",
      "Saving to: ‘ssd_pipeline.config’\n",
      "\n",
      "ssd_pipeline.config 100%[===================>]   4.68K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-01-11 21:38:20 (85.3 MB/s) - ‘ssd_pipeline.config’ saved [4788/4788]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# config files can be edited and updated on ayoubbensakhria/TensorFlowOD repository\n",
    "# Faster R-CNN Pipeline\n",
    "if os.path.isfile('pipeline.config'):\n",
    "    !rm 'pipeline.config'\n",
    "\n",
    "if os.path.isfile('ssd_pipeline.config'):\n",
    "    !rm 'ssd_pipeline.config'\n",
    "    \n",
    "# Download the latest base pipeline config file\n",
    "!wget https://raw.githubusercontent.com/ayoubbensakhria/TensorFlowOD/master/7144COMP/training/pipeline.config\n",
    "!wget https://raw.githubusercontent.com/ayoubbensakhria/TensorFlowOD/master/7144COMP/training/ssd_pipeline.config\n",
    "\n",
    "# data_augmentation_options section has been removed because it has been done by Roboflow\n",
    "base_config_path_fasterrcnn = 'pipeline.config'\n",
    "base_config_path_ssd = 'ssd_pipeline.config'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91873a86-341a-477c-9183-7f98288807a1",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "\n",
    "Our approach consists of incrementally training our model by 1000 steps and monitoring the train and validation loss as evaluation metrics. The training process will continue until the validation loss has not improved for a certain number of epochs, at which point the training process is stopped.\n",
    "\n",
    "After training for 8 epochs, we observed that the validation loss did not improve after the 7th epoch (21000 steps).\n",
    "\n",
    "```num_epochs=7``` = one forward pass and one backward pass of all the training examples. One step takes on average 2 seconds, an epoch consists of 3000 steps (batch_size=1). \n",
    "\n",
    "However, for most real-world datasets, it may not be sufficient to train a model to good performance, as the model will not have the opportunity to learn from the entire dataset.\n",
    "\n",
    "```batch_size=1``` = the number of training examples in one forward/backward pass (1 step). The higher the batch_size, the more memory space we would need. Here the available memory allows a max of batch_size = 1 \n",
    "\n",
    "```num_steps=21000```: number of iterations, or a single update of the model weights.\n",
    "\n",
    "```fixed_shape_resizer```: a fixed resolution of ```640x640 px``` is useful for ensuring that all input images have the same size, which can make them easier to process and may improve the performance of the model.\n",
    "\n",
    "```grid_anchor_generator```: anchor boxes are used to identify potential object locations within the image. The performance of a Faster R-CNN model can be affected by the parameters of the grid anchor generator such as ```scales```, ```aspect_ratios```, ```height_stride```, ```width_stride```, and it may be necessary to experiment with different values to find the best performing configuration.\n",
    "\n",
    "```second_stage_post_processing```: is responsible for taking the output of the model's second stage (the region proposal network) and generating the final set of object detections. The specific parameters used can have a significant impact on the model's performance.\n",
    "\n",
    "```learning_rate_base```: .0004: the step size at which our ```momentum_optimizer``` makes updates to the model parameters during training.\n",
    "\n",
    "\n",
    "The hyperparameters above were tuned after several experiments taking into account the model's performance metrics and the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4bbfc0c-07e4-4e3f-92b4-d4aaea92f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config the Model Pipeline Edition function\n",
    "def edit_config(model_name, base_config_path, fine_tune_checkpoint):\n",
    "  with open(base_config_path) as f:\n",
    "    config = f.read()\n",
    "\n",
    "  with open('{model}_config.config'.format(model=model_name), 'w') as f:\n",
    "\n",
    "    # Set labelmap path\n",
    "    config = re.sub('label_map_path: \".*?\"', \n",
    "              'label_map_path: \"{}\"'.format(labelmap_path), config)\n",
    "    \n",
    "    # Set fine_tune_checkpoint path\n",
    "    config = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "                    'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), config)\n",
    "\n",
    "    # Set train tf-record file path\n",
    "    config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', \n",
    "                    'input_path: \"{}\"'.format(train_record_path), config)\n",
    "\n",
    "    # Set test tf-record file path\n",
    "    config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', \n",
    "                    'input_path: \"{}\"'.format(test_record_path), config)\n",
    "\n",
    "    # Set number of classes.\n",
    "    config = re.sub('num_classes: [0-9]+',\n",
    "                    'num_classes: {}'.format(4), config)\n",
    "\n",
    "    # Set batch size\n",
    "    config = re.sub('batch_size: [0-9]+',\n",
    "                    'batch_size: {}'.format(BATCH_SIZE), config)\n",
    "\n",
    "    # Set training steps\n",
    "    config = re.sub('num_steps: [0-9]+',\n",
    "                    'num_steps: {}'.format(NUM_STEPS), config)\n",
    "\n",
    "    # Set fine-tune checkpoint type to detection\n",
    "    config = re.sub('fine_tune_checkpoint_type: \"classification\"', \n",
    "              'fine_tune_checkpoint_type: \"{}\"'.format('detection'), config)\n",
    "\n",
    "    f.write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "759e49af-1222-4db7-9442-3c590c9f4314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Faster R-CNN with Resnet-101 (v1)\n",
      "# Trained on COCO, initialized from Imagenet classification checkpoint\n",
      "\n",
      "# This config is TPU compatible.\n",
      "\n",
      "model {\n",
      "  faster_rcnn {\n",
      "    num_classes: 4\n",
      "    image_resizer {\n",
      "      fixed_shape_resizer {\n",
      "        width: 640\n",
      "        height: 640\n",
      "      }\n",
      "    }\n",
      "    feature_extractor {\n",
      "      type: 'faster_rcnn_resnet101_keras'\n",
      "      batch_norm_trainable: true\n",
      "    }\n",
      "    first_stage_anchor_generator {\n",
      "      grid_anchor_generator {\n",
      "        scales: [0.25, 0.5, 1.0, 2.0]\n",
      "        aspect_ratios: [0.5, 1.0, 2.0]\n",
      "        height_stride: 16\n",
      "        width_stride: 16\n",
      "      }\n",
      "    }\n",
      "    first_stage_box_predictor_conv_hyperparams {\n",
      "      op: CONV\n",
      "      regularizer {\n",
      "        l2_regularizer {\n",
      "          weight: 0.0\n",
      "        }\n",
      "      }\n",
      "      initializer {\n",
      "        truncated_normal_initializer {\n",
      "          stddev: 0.01\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    first_stage_nms_score_threshold: 0.0\n",
      "    first_stage_nms_iou_threshold: 0.7\n",
      "    first_stage_max_proposals: 300\n",
      "    first_stage_localization_loss_weight: 2.0\n",
      "    first_stage_objectness_loss_weight: 1.0\n",
      "    initial_crop_size: 14\n",
      "    maxpool_kernel_size: 2\n",
      "    maxpool_stride: 2\n",
      "    second_stage_box_predictor {\n",
      "      mask_rcnn_box_predictor {\n",
      "        use_dropout: false\n",
      "        dropout_keep_probability: 1.0\n",
      "        fc_hyperparams {\n",
      "          op: FC\n",
      "          regularizer {\n",
      "            l2_regularizer {\n",
      "              weight: 0.0\n",
      "            }\n",
      "          }\n",
      "          initializer {\n",
      "            variance_scaling_initializer {\n",
      "              factor: 1.0\n",
      "              uniform: true\n",
      "              mode: FAN_AVG\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        share_box_across_classes: true\n",
      "      }\n",
      "    }\n",
      "    second_stage_post_processing {\n",
      "      batch_non_max_suppression {\n",
      "        score_threshold: 0.0\n",
      "        iou_threshold: 0.6\n",
      "        max_detections_per_class: 100\n",
      "        max_total_detections: 300\n",
      "      }\n",
      "      score_converter: SOFTMAX\n",
      "    }\n",
      "    second_stage_localization_loss_weight: 2.0\n",
      "    second_stage_classification_loss_weight: 1.0\n",
      "    use_static_shapes: true\n",
      "    use_matmul_crop_and_resize: true\n",
      "    clip_anchors_to_image: true\n",
      "    use_static_balanced_label_sampler: true\n",
      "    use_matmul_gather_in_matcher: true\n",
      "  }\n",
      "}\n",
      "\n",
      "train_config: {\n",
      "  batch_size: 1\n",
      "  sync_replicas: true\n",
      "  startup_delay_steps: 0\n",
      "  replicas_to_aggregate: 8\n",
      "  num_steps: 21000\n",
      "  optimizer {\n",
      "    momentum_optimizer: {\n",
      "      learning_rate: {\n",
      "        cosine_decay_learning_rate {\n",
      "          learning_rate_base: .0004\n",
      "          total_steps: 100000\n",
      "          warmup_learning_rate: .00004\n",
      "          warmup_steps: 2000\n",
      "        }\n",
      "      }\n",
      "      momentum_optimizer_value: 0.9\n",
      "    }\n",
      "    use_moving_average: false\n",
      "  }\n",
      "  fine_tune_checkpoint_version: V2\n",
      "  fine_tune_checkpoint: \"faster_rcnn_resnet101_v1_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
      "  fine_tune_checkpoint_type: \"detection\"\n",
      "  data_augmentation_options {\n",
      "    random_horizontal_flip {\n",
      "    }\n",
      "  }\n",
      "\n",
      "  data_augmentation_options {\n",
      "    random_adjust_hue {\n",
      "    }\n",
      "  }\n",
      "\n",
      "  data_augmentation_options {\n",
      "    random_adjust_contrast {\n",
      "    }\n",
      "  }\n",
      "\n",
      "  data_augmentation_options {\n",
      "    random_adjust_saturation {\n",
      "    }\n",
      "  }\n",
      "\n",
      "  data_augmentation_options {\n",
      "     random_square_crop_by_scale {\n",
      "      scale_min: 0.6\n",
      "      scale_max: 1.3\n",
      "    }\n",
      "  }\n",
      "  max_number_of_boxes: 100\n",
      "  unpad_groundtruth_tensors: false\n",
      "  use_bfloat16: false  # works only on TPUs\n",
      "}\n",
      "\n",
      "train_input_reader: {\n",
      "  label_map_path: \"/home/msc1/Desktop/7144COMP/Models/faster_rcnn_resnet101/Birds/train/birds_label_map.pbtxt\"\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/home/msc1/Desktop/7144COMP/Models/faster_rcnn_resnet101/Birds/train/birds.tfrecord\"\n",
      "  }\n",
      "}\n",
      "\n",
      "eval_config: {\n",
      "  metrics_set: \"coco_detection_metrics\"\n",
      "  use_moving_averages: false\n",
      "  batch_size: 1;\n",
      "}\n",
      "\n",
      "eval_input_reader: {\n",
      "  label_map_path: \"/home/msc1/Desktop/7144COMP/Models/faster_rcnn_resnet101/Birds/train/birds_label_map.pbtxt\"\n",
      "  shuffle: false\n",
      "  num_epochs: 1\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/home/msc1/Desktop/7144COMP/Models/faster_rcnn_resnet101/Birds/test/birds.tfrecord\"\n",
      "  }\n",
      "}"
     ]
    }
   ],
   "source": [
    "# Edit config Fatser R-CNN\n",
    "edit_config('fasterrcnn', base_config_path_fasterrcnn, fine_tune_checkpoint_fasterrcnn)\n",
    "\n",
    "# Clean up\n",
    "!rm 'pipeline.config'\n",
    "\n",
    "# Print config pipeline\n",
    "%cat 'fasterrcnn_config.config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a3a1411-e741-4494-8e86-fde4f9d417c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# SSD with Resnet 101 v1 FPN feature extractor, shared box predictor and focal\n",
      "# loss (a.k.a Retinanet).\n",
      "# See Lin et al, https://arxiv.org/abs/1708.02002\n",
      "# Trained on COCO, initialized from Imagenet classification checkpoint\n",
      "# Train on TPU-8\n",
      "#\n",
      "# Achieves 35.4 mAP on COCO17 Val\n",
      "\n",
      "model {\n",
      "  ssd {\n",
      "    num_classes: 4\n",
      "    image_resizer {\n",
      "      fixed_shape_resizer {\n",
      "        height: 640\n",
      "        width: 640\n",
      "      }\n",
      "    }\n",
      "    feature_extractor {\n",
      "      type: \"ssd_resnet101_v1_fpn_keras\"\n",
      "      depth_multiplier: 1.0\n",
      "      min_depth: 16\n",
      "      conv_hyperparams {\n",
      "        regularizer {\n",
      "          l2_regularizer {\n",
      "            weight: 0.00039999998989515007\n",
      "          }\n",
      "        }\n",
      "        initializer {\n",
      "          truncated_normal_initializer {\n",
      "            mean: 0.0\n",
      "            stddev: 0.029999999329447746\n",
      "          }\n",
      "        }\n",
      "        activation: RELU_6\n",
      "        batch_norm {\n",
      "          decay: 0.996999979019165\n",
      "          scale: true\n",
      "          epsilon: 0.0010000000474974513\n",
      "        }\n",
      "      }\n",
      "      override_base_feature_extractor_hyperparams: true\n",
      "      fpn {\n",
      "        min_level: 3\n",
      "        max_level: 7\n",
      "      }\n",
      "    }\n",
      "    box_coder {\n",
      "      faster_rcnn_box_coder {\n",
      "        y_scale: 10.0\n",
      "        x_scale: 10.0\n",
      "        height_scale: 5.0\n",
      "        width_scale: 5.0\n",
      "      }\n",
      "    }\n",
      "    matcher {\n",
      "      argmax_matcher {\n",
      "        matched_threshold: 0.5\n",
      "        unmatched_threshold: 0.5\n",
      "        ignore_thresholds: false\n",
      "        negatives_lower_than_unmatched: true\n",
      "        force_match_for_each_row: true\n",
      "        use_matmul_gather: true\n",
      "      }\n",
      "    }\n",
      "    similarity_calculator {\n",
      "      iou_similarity {\n",
      "      }\n",
      "    }\n",
      "    box_predictor {\n",
      "      weight_shared_convolutional_box_predictor {\n",
      "        conv_hyperparams {\n",
      "          regularizer {\n",
      "            l2_regularizer {\n",
      "              weight: 0.00039999998989515007\n",
      "            }\n",
      "          }\n",
      "          initializer {\n",
      "            random_normal_initializer {\n",
      "              mean: 0.0\n",
      "              stddev: 0.009999999776482582\n",
      "            }\n",
      "          }\n",
      "          activation: RELU_6\n",
      "          batch_norm {\n",
      "            decay: 0.996999979019165\n",
      "            scale: true\n",
      "            epsilon: 0.0010000000474974513\n",
      "          }\n",
      "        }\n",
      "        depth: 256\n",
      "        num_layers_before_predictor: 4\n",
      "        kernel_size: 3\n",
      "        class_prediction_bias_init: -4.599999904632568\n",
      "      }\n",
      "    }\n",
      "    anchor_generator {\n",
      "      multiscale_anchor_generator {\n",
      "        min_level: 3\n",
      "        max_level: 7\n",
      "        anchor_scale: 4.0\n",
      "        aspect_ratios: 1.0\n",
      "        aspect_ratios: 2.0\n",
      "        aspect_ratios: 0.5\n",
      "        scales_per_octave: 2\n",
      "      }\n",
      "    }\n",
      "    post_processing {\n",
      "      batch_non_max_suppression {\n",
      "        score_threshold: 9.99999993922529e-09\n",
      "        iou_threshold: 0.6000000238418579\n",
      "        max_detections_per_class: 100\n",
      "        max_total_detections: 100\n",
      "        use_static_shapes: false\n",
      "      }\n",
      "      score_converter: SIGMOID\n",
      "    }\n",
      "    normalize_loss_by_num_matches: true\n",
      "    loss {\n",
      "      localization_loss {\n",
      "        weighted_smooth_l1 {\n",
      "        }\n",
      "      }\n",
      "      classification_loss {\n",
      "        weighted_sigmoid_focal {\n",
      "          gamma: 2.0\n",
      "          alpha: 0.25\n",
      "        }\n",
      "      }\n",
      "      classification_weight: 1.0\n",
      "      localization_weight: 1.0\n",
      "    }\n",
      "    encode_background_as_zeros: true\n",
      "    normalize_loc_loss_by_codesize: true\n",
      "    inplace_batchnorm_update: true\n",
      "    freeze_batchnorm: false\n",
      "  }\n",
      "}\n",
      "train_config {\n",
      "  batch_size: 1\n",
      "  data_augmentation_options {\n",
      "    random_horizontal_flip {\n",
      "    }\n",
      "  }\n",
      "  data_augmentation_options {\n",
      "    random_crop_image {\n",
      "      min_object_covered: 0.0\n",
      "      min_aspect_ratio: 0.75\n",
      "      max_aspect_ratio: 3.0\n",
      "      min_area: 0.75\n",
      "      max_area: 1.0\n",
      "      overlap_thresh: 0.0\n",
      "    }\n",
      "  }\n",
      "  sync_replicas: true\n",
      "  optimizer {\n",
      "    momentum_optimizer {\n",
      "      learning_rate {\n",
      "        cosine_decay_learning_rate {\n",
      "          learning_rate_base: 0.03999999910593033\n",
      "          total_steps: 25000\n",
      "          warmup_learning_rate: 0.013333000242710114\n",
      "          warmup_steps: 2000\n",
      "        }\n",
      "      }\n",
      "      momentum_optimizer_value: 0.8999999761581421\n",
      "    }\n",
      "    use_moving_average: false\n",
      "  }\n",
      "  fine_tune_checkpoint: \"ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
      "  num_steps: 21000\n",
      "  startup_delay_steps: 0.0\n",
      "  replicas_to_aggregate: 8\n",
      "  max_number_of_boxes: 100\n",
      "  unpad_groundtruth_tensors: false\n",
      "  fine_tune_checkpoint_type: \"detection\"\n",
      "  use_bfloat16: true\n",
      "  fine_tune_checkpoint_version: V2\n",
      "}\n",
      "\n",
      "train_input_reader: {\n",
      "  label_map_path: \"/home/msc1/Desktop/7144COMP/Models/faster_rcnn_resnet101/Birds/train/birds_label_map.pbtxt\"\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/home/msc1/Desktop/7144COMP/Models/faster_rcnn_resnet101/Birds/train/birds.tfrecord\"\n",
      "  }\n",
      "}\n",
      "\n",
      "eval_config: {\n",
      "  metrics_set: \"coco_detection_metrics\"\n",
      "  use_moving_averages: false\n",
      "}\n",
      "\n",
      "eval_input_reader: {\n",
      "  label_map_path: \"/home/msc1/Desktop/7144COMP/Models/faster_rcnn_resnet101/Birds/train/birds_label_map.pbtxt\"\n",
      "  shuffle: false\n",
      "  num_epochs: 1\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/home/msc1/Desktop/7144COMP/Models/faster_rcnn_resnet101/Birds/test/birds.tfrecord\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Edit config SSD\n",
    "edit_config('ssd', base_config_path_ssd, fine_tune_checkpoint_ssd)\n",
    "\n",
    "# Clean up\n",
    "!rm 'ssd_pipeline.config'\n",
    "\n",
    "# Print config pipeline\n",
    "%cat 'ssd_config.config'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4423e2-dc2d-4fc5-b415-411ad8472fa6",
   "metadata": {},
   "source": [
    "# 3. Train Faster R-CNN and SSD ResNet101 Object Detectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b426319-410a-4fe7-9048-2c1fa44fbc34",
   "metadata": {},
   "source": [
    "- The validation script must be run concurrently with the training script in order to visualise the validation loss curve on ```TensorBoard```. \n",
    "- The validation script should be listening to new checkpoints (output: ```Waiting for new checkpoint at``` ...) to execute valiadation each ```1000 steps``` (see part 3). \n",
    "- Due to the limitation of resources, the servers stopped many times and the evaluation script timed out, so I had to monitor it regularly, and restart the train and/or the eval scripts again manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aac4df-a7c6-4dbf-bd7a-c22d3b5aac0a",
   "metadata": {},
   "source": [
    "#### Faster RCNN Model training directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66b12179-4237-4a7a-b6d8-b44af44a4311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasterrcnn_config.config /home/msc1/Desktop/7144COMP/Models/faster_rcnn_resnet101/training 21000\n"
     ]
    }
   ],
   "source": [
    "# Faster RCNN Model training directory and config pipeline\n",
    "model_dir = os.path.join(current_dir, 'training')\n",
    "pipeline_config_path = 'fasterrcnn_config.config'\n",
    "\n",
    "# Test training params\n",
    "print (pipeline_config_path, model_dir, NUM_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333704d4-3f38-424d-bcdb-ac64ad40b27d",
   "metadata": {},
   "source": [
    "#### SSD Model training directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "545363b9-52d4-45e4-8a63-bd578e71bf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasterrcnn_config.config /home/msc1/Desktop/7144COMP/Models/faster_rcnn_resnet101/training_ssd 21000\n"
     ]
    }
   ],
   "source": [
    "# SSD Model training directory and config pipeline\n",
    "model_dir_ssd = os.path.join(current_dir, 'training_ssd')\n",
    "pipeline_config_path_ssd = 'ssd_config.config'\n",
    "\n",
    "# Test training params\n",
    "print (pipeline_config_path, model_dir_ssd, NUM_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc3df9e-5e74-4182-8d99-795703ce77bf",
   "metadata": {},
   "source": [
    "#### Train and save OD graph of Faster RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bfd290d7-913e-455e-ba84-9f0881eff8f4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-09 06:58:52.716373: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-09 06:58:53.498698: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2023-01-09 06:58:53.498749: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2023-01-09 06:58:53.498757: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-01-09 06:58:54.907706: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2023-01-09 06:58:54.907736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: CMPR01\n",
      "2023-01-09 06:58:54.907744: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: CMPR01\n",
      "2023-01-09 06:58:54.907800: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.161.3\n",
      "2023-01-09 06:58:54.907819: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.91.3\n",
      "2023-01-09 06:58:54.907826: E tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 460.91.3 does not match DSO version 470.161.3 -- cannot find working devices in this configuration\n",
      "2023-01-09 06:58:54.908106: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "W0109 06:58:54.909467 140577363105600 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I0109 06:58:54.921233 140577363105600 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 21000\n",
      "I0109 06:58:54.923532 140577363105600 config_util.py:552] Maybe overwriting train_steps: 21000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0109 06:58:54.923613 140577363105600 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0109 06:58:54.951417 140577363105600 deprecation.py:350] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/home/msc1/Desktop/7144COMP/Models/faster_rcnn_resnet101/Birds/train/birds.tfrecord']\n",
      "I0109 06:58:54.957276 140577363105600 dataset_builder.py:162] Reading unweighted datasets: ['/home/msc1/Desktop/7144COMP/Models/faster_rcnn_resnet101/Birds/train/birds.tfrecord']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/home/msc1/Desktop/7144COMP/Models/faster_rcnn_resnet101/Birds/train/birds.tfrecord']\n",
      "I0109 06:58:54.957391 140577363105600 dataset_builder.py:79] Reading record datasets for input file: ['/home/msc1/Desktop/7144COMP/Models/faster_rcnn_resnet101/Birds/train/birds.tfrecord']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0109 06:58:54.957449 140577363105600 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0109 06:58:54.957497 140577363105600 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0109 06:58:54.962236 140577363105600 deprecation.py:350] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0109 06:58:54.975362 140577363105600 deprecation.py:350] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "W0109 06:58:55.380988 140577363105600 deprecation.py:350] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0109 06:58:59.779355 140577363105600 deprecation.py:350] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0109 06:59:03.010577 140577363105600 deprecation.py:350] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2023-01-09 06:59:04.895280: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "/home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/keras/backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0109 06:59:10.302092 140567770035968 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:459: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "W0109 06:59:15.356849 140567770035968 deprecation.py:350] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:459: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W0109 06:59:19.008596 140567770035968 deprecation.py:350] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "2023-01-09 06:59:27.058445: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 963379200 exceeds 10% of free system memory.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0109 06:59:32.266213 140568290121472 deprecation.py:554] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "INFO:tensorflow:Step 20100 per-step time 2.219s\n",
      "I0109 07:03:13.861733 140577363105600 model_lib_v2.py:705] Step 20100 per-step time 2.219s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.0715713,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.12126283,\n",
      " 'Loss/RPNLoss/localization_loss': 0.009487195,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.010712221,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.21303356,\n",
      " 'learning_rate': 0.00036726697}\n",
      "I0109 07:03:13.862060 140577363105600 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.0715713,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.12126283,\n",
      " 'Loss/RPNLoss/localization_loss': 0.009487195,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.010712221,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.21303356,\n",
      " 'learning_rate': 0.00036726697}\n",
      "INFO:tensorflow:Step 20200 per-step time 1.911s\n",
      "I0109 07:06:24.952271 140577363105600 model_lib_v2.py:705] Step 20200 per-step time 1.911s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.11460991,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.06306716,\n",
      " 'Loss/RPNLoss/localization_loss': 0.005080689,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.019280963,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.20203872,\n",
      " 'learning_rate': 0.00036691464}\n",
      "I0109 07:06:24.952458 140577363105600 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.11460991,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.06306716,\n",
      " 'Loss/RPNLoss/localization_loss': 0.005080689,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.019280963,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.20203872,\n",
      " 'learning_rate': 0.00036691464}\n",
      "INFO:tensorflow:Step 20300 per-step time 1.926s\n",
      "I0109 07:09:37.589342 140577363105600 model_lib_v2.py:705] Step 20300 per-step time 1.926s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.21322471,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.39415327,\n",
      " 'Loss/RPNLoss/localization_loss': 0.020753792,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.031229053,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.6593609,\n",
      " 'learning_rate': 0.0003665606}\n",
      "I0109 07:09:37.589530 140577363105600 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.21322471,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.39415327,\n",
      " 'Loss/RPNLoss/localization_loss': 0.020753792,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.031229053,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.6593609,\n",
      " 'learning_rate': 0.0003665606}\n",
      "INFO:tensorflow:Step 20400 per-step time 1.920s\n",
      "I0109 07:12:49.575549 140577363105600 model_lib_v2.py:705] Step 20400 per-step time 1.920s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.049657833,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.17497426,\n",
      " 'Loss/RPNLoss/localization_loss': 0.05989827,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.016080583,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.30061093,\n",
      " 'learning_rate': 0.00036620483}\n",
      "I0109 07:12:49.575736 140577363105600 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.049657833,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.17497426,\n",
      " 'Loss/RPNLoss/localization_loss': 0.05989827,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.016080583,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.30061093,\n",
      " 'learning_rate': 0.00036620483}\n",
      "INFO:tensorflow:Step 20500 per-step time 1.914s\n",
      "I0109 07:16:00.950717 140577363105600 model_lib_v2.py:705] Step 20500 per-step time 1.914s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.03719121,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.14062402,\n",
      " 'Loss/RPNLoss/localization_loss': 0.007978139,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0015022417,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.18729562,\n",
      " 'learning_rate': 0.00036584734}\n",
      "I0109 07:16:00.950902 140577363105600 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.03719121,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.14062402,\n",
      " 'Loss/RPNLoss/localization_loss': 0.007978139,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0015022417,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.18729562,\n",
      " 'learning_rate': 0.00036584734}\n",
      "INFO:tensorflow:Step 20600 per-step time 1.911s\n",
      "I0109 07:19:12.048241 140577363105600 model_lib_v2.py:705] Step 20600 per-step time 1.911s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.36291397,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.5481061,\n",
      " 'Loss/RPNLoss/localization_loss': 0.21811284,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.4722691,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 1.6014019,\n",
      " 'learning_rate': 0.00036548814}\n",
      "I0109 07:19:12.048433 140577363105600 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.36291397,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.5481061,\n",
      " 'Loss/RPNLoss/localization_loss': 0.21811284,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.4722691,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 1.6014019,\n",
      " 'learning_rate': 0.00036548814}\n",
      "INFO:tensorflow:Step 20700 per-step time 1.917s\n",
      "I0109 07:22:23.726848 140577363105600 model_lib_v2.py:705] Step 20700 per-step time 1.917s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.0463763,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.033502787,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0017504157,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0027463017,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.084375806,\n",
      " 'learning_rate': 0.00036512726}\n",
      "I0109 07:22:23.727038 140577363105600 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.0463763,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.033502787,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0017504157,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0027463017,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.084375806,\n",
      " 'learning_rate': 0.00036512726}\n",
      "INFO:tensorflow:Step 20800 per-step time 1.918s\n",
      "I0109 07:25:35.534072 140577363105600 model_lib_v2.py:705] Step 20800 per-step time 1.918s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.080344275,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.07215808,\n",
      " 'Loss/RPNLoss/localization_loss': 0.005697885,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.02618659,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.18438683,\n",
      " 'learning_rate': 0.00036476468}\n",
      "I0109 07:25:35.534260 140577363105600 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.080344275,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.07215808,\n",
      " 'Loss/RPNLoss/localization_loss': 0.005697885,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.02618659,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.18438683,\n",
      " 'learning_rate': 0.00036476468}\n",
      "INFO:tensorflow:Step 20900 per-step time 1.914s\n",
      "I0109 07:28:46.929350 140577363105600 model_lib_v2.py:705] Step 20900 per-step time 1.914s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.06914408,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.02732196,\n",
      " 'Loss/RPNLoss/localization_loss': 0.008750749,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0028063538,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.10802314,\n",
      " 'learning_rate': 0.0003644004}\n",
      "I0109 07:28:46.929542 140577363105600 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.06914408,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.02732196,\n",
      " 'Loss/RPNLoss/localization_loss': 0.008750749,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0028063538,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.10802314,\n",
      " 'learning_rate': 0.0003644004}\n",
      "INFO:tensorflow:Step 21000 per-step time 1.912s\n",
      "I0109 07:31:58.176448 140577363105600 model_lib_v2.py:705] Step 21000 per-step time 1.912s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.07851274,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.010655317,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0007284929,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0010009607,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.090897515,\n",
      " 'learning_rate': 0.00036403447}\n",
      "I0109 07:31:58.176636 140577363105600 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.07851274,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.010655317,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0007284929,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0010009607,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.090897515,\n",
      " 'learning_rate': 0.00036403447}\n"
     ]
    }
   ],
   "source": [
    "# Execute training\n",
    "!python $current_dir/models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path=$pipeline_config_path \\\n",
    "    --model_dir=$model_dir \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps=$NUM_STEPS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae63895-aa91-4ef8-9181-939af6da055d",
   "metadata": {},
   "source": [
    "The script above was used to train an object detection model using ```TensorFlow 2```. It takes in a pipeline configuration file, which specifies the model and training configuration, and a set of training and evaluation data.\n",
    "\n",
    "The script has several flags that can be used to control the training process. \n",
    "\n",
    "- ```--pipeline_config_path```  specifies the path to the pipeline configuration file, which defines the model architecture and training parameters. \n",
    "\n",
    "- ```--model_dir```  specifies the directory where the trained model and training logs should be saved. The --alsologtostderr flag causes the training logs to be written to both the log file and the console.\n",
    "\n",
    "- ```--num_train_steps```  specifies the number of training steps to run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c07bbbb-12b4-4e45-8ae4-d430c15dce9e",
   "metadata": {},
   "source": [
    "### Export Faster RCNN OD inference graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e899df8e-8d20-4265-a9fb-3d244ad1af28",
   "metadata": {},
   "source": [
    "Graphs are data structures that contain a set of ```tf.Operation``` objects, which represent units of computation; and ```tf.Tensor``` objects, which represent the units of data that flow between operations. \n",
    "\n",
    "Here we will save our object detection inference graph files in ```fasterrcnn_inference_graph/saved_model```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10716f79-fc88-453f-9e57-e32b270eaff9",
   "metadata": {
    "tags": []
   },
   "source": [
    "The following script uses the ```exporter_main_v2.py``` script from the TensorFlow object detection library to export the trained model. The script loads the trained model from the specified checkpoint directory and then uses the pipeline configuration file to create a new model (a copy of the trained model) with the same architecture. The exported model is saved in the specified output directory.\n",
    "\n",
    "This new model is a copy of the trained model, but it has been converted to a format that is suitable for serving or for further training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "061b0e3a-065c-4ca8-902a-fa7a2e671128",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-09 15:35:00.110426: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-09 15:35:00.901666: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2023-01-09 15:35:00.901715: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2023-01-09 15:35:00.901724: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-01-09 15:35:02.390419: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2023-01-09 15:35:02.390447: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: CMPR01\n",
      "2023-01-09 15:35:02.390454: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: CMPR01\n",
      "2023-01-09 15:35:02.390509: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.161.3\n",
      "2023-01-09 15:35:02.390529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.91.3\n",
      "2023-01-09 15:35:02.390536: E tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 460.91.3 does not match DSO version 470.161.3 -- cannot find working devices in this configuration\n",
      "2023-01-09 15:35:02.408877: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "W0109 15:35:02.465542 140233590327104 deprecation.py:350] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "W0109 15:35:02.526448 140233590327104 deprecation.py:623] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0109 15:35:08.212137 140233590327104 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:459: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "W0109 15:35:13.456008 140233590327104 deprecation.py:350] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:459: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.faster_rcnn_meta_arch.FasterRCNNMetaArch object at 0x7f89ee7b4ca0>, because it is not built.\n",
      "W0109 15:35:21.921808 140233590327104 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.faster_rcnn_meta_arch.FasterRCNNMetaArch object at 0x7f89ee7b4ca0>, because it is not built.\n",
      "W0109 15:35:39.344835 140233590327104 save.py:271] Found untraced functions such as FirstStageBoxPredictor_layer_call_fn, FirstStageBoxPredictor_layer_call_and_return_conditional_losses, mask_rcnn_keras_box_predictor_layer_call_fn, mask_rcnn_keras_box_predictor_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op while saving (showing 5 of 135). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: fasterrcnn_inference_graph/saved_model/assets\n",
      "I0109 15:35:45.459352 140233590327104 builder_impl.py:797] Assets written to: fasterrcnn_inference_graph/saved_model/assets\n",
      "INFO:tensorflow:Writing pipeline config file to fasterrcnn_inference_graph/pipeline.config\n",
      "I0109 15:35:46.742287 140233590327104 config_util.py:253] Writing pipeline config file to fasterrcnn_inference_graph/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "# Define the output directory\n",
    "output_directory = 'fasterrcnn_inference_graph'\n",
    "\n",
    "# Export OD inference graph\n",
    "!python $current_dir/models/research/object_detection/exporter_main_v2.py \\\n",
    "    --trained_checkpoint_dir $model_dir \\\n",
    "    --output_directory $output_directory \\\n",
    "    --pipeline_config_path $pipeline_config_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5d0820-e43e-4c36-bd04-8abe984dfa5f",
   "metadata": {},
   "source": [
    "- ``` trained_checkpoint_dir``` : Directory containing the trained model checkpoints.\n",
    "- ``` output_directory``` : Directory where the exported model will be saved.\n",
    "- ``` pipeline_config_path``` : Path to the pipeline configuration file, which specifies the model architecture and other options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d435cf-e5b2-4f8c-8d48-887475cb2f5d",
   "metadata": {},
   "source": [
    "#### Train and Save SSD Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9102ae9-5f0e-4a5b-b309-5ac865e4da9f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-11 23:27:28.447361: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-11 23:27:29.238385: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2023-01-11 23:27:29.238435: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2023-01-11 23:27:29.238444: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-01-11 23:27:30.901162: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2023-01-11 23:27:30.901187: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: CMPR01\n",
      "2023-01-11 23:27:30.901195: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: CMPR01\n",
      "2023-01-11 23:27:30.901250: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.161.3\n",
      "2023-01-11 23:27:30.901270: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.91.3\n",
      "2023-01-11 23:27:30.901276: E tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 460.91.3 does not match DSO version 470.161.3 -- cannot find working devices in this configuration\n",
      "2023-01-11 23:27:30.901741: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "W0111 23:27:30.903076 139882563934016 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I0111 23:27:30.915549 139882563934016 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 21000\n",
      "I0111 23:27:30.918380 139882563934016 config_util.py:552] Maybe overwriting train_steps: 21000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0111 23:27:30.918467 139882563934016 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0111 23:27:30.940600 139882563934016 deprecation.py:350] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/home/msc1/Desktop/7144COMP/Models/faster_rcnn_resnet101/Birds/train/birds.tfrecord']\n",
      "I0111 23:27:30.947345 139882563934016 dataset_builder.py:162] Reading unweighted datasets: ['/home/msc1/Desktop/7144COMP/Models/faster_rcnn_resnet101/Birds/train/birds.tfrecord']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/home/msc1/Desktop/7144COMP/Models/faster_rcnn_resnet101/Birds/train/birds.tfrecord']\n",
      "I0111 23:27:30.947459 139882563934016 dataset_builder.py:79] Reading record datasets for input file: ['/home/msc1/Desktop/7144COMP/Models/faster_rcnn_resnet101/Birds/train/birds.tfrecord']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0111 23:27:30.947516 139882563934016 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0111 23:27:30.947565 139882563934016 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0111 23:27:30.952126 139882563934016 deprecation.py:350] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0111 23:27:30.965892 139882563934016 deprecation.py:350] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "W0111 23:27:31.382481 139882563934016 deprecation.py:350] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0111 23:27:35.818186 139882563934016 deprecation.py:350] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0111 23:27:38.105449 139882563934016 deprecation.py:350] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0111 23:27:39.313954 139882563934016 deprecation.py:350] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2023-01-11 23:27:41.191254: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "/home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/keras/backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0111 23:28:03.313711 139873629484800 deprecation.py:554] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "INFO:tensorflow:Step 2100 per-step time 2.287s\n",
      "I0111 23:31:51.753030 139882563934016 model_lib_v2.py:705] Step 2100 per-step time 2.287s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 1.5333929,\n",
      " 'Loss/localization_loss': 0.93766636,\n",
      " 'Loss/regularization_loss': 20.047047,\n",
      " 'Loss/total_loss': 22.518106,\n",
      " 'learning_rate': 0.039998136}\n",
      "I0111 23:31:51.753227 139882563934016 model_lib_v2.py:708] {'Loss/classification_loss': 1.5333929,\n",
      " 'Loss/localization_loss': 0.93766636,\n",
      " 'Loss/regularization_loss': 20.047047,\n",
      " 'Loss/total_loss': 22.518106,\n",
      " 'learning_rate': 0.039998136}\n",
      "INFO:tensorflow:Step 2200 per-step time 2.000s\n",
      "I0111 23:35:11.778494 139882563934016 model_lib_v2.py:705] Step 2200 per-step time 2.000s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.97516304,\n",
      " 'Loss/localization_loss': 0.7291199,\n",
      " 'Loss/regularization_loss': 19.416315,\n",
      " 'Loss/total_loss': 21.120598,\n",
      " 'learning_rate': 0.039992537}\n",
      "I0111 23:35:11.778672 139882563934016 model_lib_v2.py:708] {'Loss/classification_loss': 0.97516304,\n",
      " 'Loss/localization_loss': 0.7291199,\n",
      " 'Loss/regularization_loss': 19.416315,\n",
      " 'Loss/total_loss': 21.120598,\n",
      " 'learning_rate': 0.039992537}\n",
      "INFO:tensorflow:Step 2300 per-step time 1.996s\n",
      "I0111 23:38:31.358730 139882563934016 model_lib_v2.py:705] Step 2300 per-step time 1.996s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 1.0979055,\n",
      " 'Loss/localization_loss': 0.76879525,\n",
      " 'Loss/regularization_loss': 18.805859,\n",
      " 'Loss/total_loss': 20.67256,\n",
      " 'learning_rate': 0.03998321}\n",
      "I0111 23:38:31.358905 139882563934016 model_lib_v2.py:708] {'Loss/classification_loss': 1.0979055,\n",
      " 'Loss/localization_loss': 0.76879525,\n",
      " 'Loss/regularization_loss': 18.805859,\n",
      " 'Loss/total_loss': 20.67256,\n",
      " 'learning_rate': 0.03998321}\n",
      "INFO:tensorflow:Step 2400 per-step time 1.978s\n",
      "I0111 23:41:49.183124 139882563934016 model_lib_v2.py:705] Step 2400 per-step time 1.978s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.42995298,\n",
      " 'Loss/localization_loss': 0.5806528,\n",
      " 'Loss/regularization_loss': 18.214619,\n",
      " 'Loss/total_loss': 19.225224,\n",
      " 'learning_rate': 0.039970152}\n",
      "I0111 23:41:49.183295 139882563934016 model_lib_v2.py:708] {'Loss/classification_loss': 0.42995298,\n",
      " 'Loss/localization_loss': 0.5806528,\n",
      " 'Loss/regularization_loss': 18.214619,\n",
      " 'Loss/total_loss': 19.225224,\n",
      " 'learning_rate': 0.039970152}\n",
      "INFO:tensorflow:Step 2500 per-step time 1.983s\n",
      "I0111 23:45:07.475677 139882563934016 model_lib_v2.py:705] Step 2500 per-step time 1.983s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.60211194,\n",
      " 'Loss/localization_loss': 0.591155,\n",
      " 'Loss/regularization_loss': 17.642494,\n",
      " 'Loss/total_loss': 18.83576,\n",
      " 'learning_rate': 0.039953373}\n",
      "I0111 23:45:07.475852 139882563934016 model_lib_v2.py:708] {'Loss/classification_loss': 0.60211194,\n",
      " 'Loss/localization_loss': 0.591155,\n",
      " 'Loss/regularization_loss': 17.642494,\n",
      " 'Loss/total_loss': 18.83576,\n",
      " 'learning_rate': 0.039953373}\n",
      "INFO:tensorflow:Step 2600 per-step time 1.999s\n",
      "I0111 23:48:27.412793 139882563934016 model_lib_v2.py:705] Step 2600 per-step time 1.999s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.95407224,\n",
      " 'Loss/localization_loss': 0.6201,\n",
      " 'Loss/regularization_loss': 17.088692,\n",
      " 'Loss/total_loss': 18.662865,\n",
      " 'learning_rate': 0.03993287}\n",
      "I0111 23:48:27.412964 139882563934016 model_lib_v2.py:708] {'Loss/classification_loss': 0.95407224,\n",
      " 'Loss/localization_loss': 0.6201,\n",
      " 'Loss/regularization_loss': 17.088692,\n",
      " 'Loss/total_loss': 18.662865,\n",
      " 'learning_rate': 0.03993287}\n"
     ]
    }
   ],
   "source": [
    "# Execute training\n",
    "!python $current_dir/models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path=$pipeline_config_path_ssd \\\n",
    "    --model_dir=$model_dir_ssd \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps=$NUM_STEPS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aeb8e4-1162-414f-90dd-18abf16c5dd4",
   "metadata": {},
   "source": [
    "#### Export SSD OD Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "734b5c9a-d9ef-4615-85da-566eb8bbe5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-12 00:11:27.722640: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-12 00:11:28.867737: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2023-01-12 00:11:28.867799: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2023-01-12 00:11:28.867808: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-01-12 00:11:30.857213: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2023-01-12 00:11:30.857238: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: CMPR01\n",
      "2023-01-12 00:11:30.857245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: CMPR01\n",
      "2023-01-12 00:11:30.857297: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.161.3\n",
      "2023-01-12 00:11:30.857315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.91.3\n",
      "2023-01-12 00:11:30.857322: E tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 460.91.3 does not match DSO version 470.161.3 -- cannot find working devices in this configuration\n",
      "2023-01-12 00:11:30.861941: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "W0112 00:11:30.926766 140346539476800 deprecation.py:350] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "W0112 00:11:30.988030 140346539476800 deprecation.py:623] From /home/msc1/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fa43840e460>, because it is not built.\n",
      "W0112 00:11:49.984134 140346539476800 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fa43840e460>, because it is not built.\n",
      "W0112 00:12:16.371347 140346539476800 save.py:271] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 329). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: ssd_inference_graph/saved_model/assets\n",
      "I0112 00:12:24.471554 140346539476800 builder_impl.py:797] Assets written to: ssd_inference_graph/saved_model/assets\n",
      "INFO:tensorflow:Writing pipeline config file to ssd_inference_graph/pipeline.config\n",
      "I0112 00:12:26.134397 140346539476800 config_util.py:253] Writing pipeline config file to ssd_inference_graph/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "# Define the output directory\n",
    "output_directory_ssd = 'ssd_inference_graph'\n",
    "\n",
    "# Export OD inference graph\n",
    "!python $current_dir/models/research/object_detection/exporter_main_v2.py \\\n",
    "    --trained_checkpoint_dir $model_dir_ssd \\\n",
    "    --output_directory $output_directory_ssd \\\n",
    "    --pipeline_config_path $pipeline_config_path_ssd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993f89a5-f50a-43ad-9496-ce255a61f27c",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Evaluate the trained model using TensorBoard."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlowGPU",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
