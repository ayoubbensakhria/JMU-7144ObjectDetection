{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa082d3-1ce9-4020-a41d-9c72aad71756",
   "metadata": {},
   "source": [
    "# 7144COMP/CW2: Bird Multiple Object Detection Using Faster R-CNN ResNet101 Network \n",
    "## PART IV: Model evaluation and deployment\n",
    "\n",
    "### Overview\n",
    "\n",
    "In this notebook, I will evaluate my model through TensorBoard while using the generated metrics to determine model convergence (both validation loss and Intersection over Union (IoU) at both 0.5 and 0.75 are considered). \n",
    "\n",
    "The number of epochs to train the model is set to 1, the reason for this choice was explained in the training notebook. In addition, during the 1st epoch of training, the model converged around the final loss value (smoothed loss value with a weight of 0.8).\n",
    "\n",
    "\n",
    "\n",
    "For the current task, the following steps have been undertaken: \n",
    "\n",
    "- Launch TensorBoard displaying both the train and evaluation metrics for the given session. \n",
    "- Provide justification for the number of epochs used for training your object detection model\n",
    "\n",
    "### Next\n",
    "\n",
    "In the next notebook which is an extension to the present, I will:\n",
    "\n",
    "- Freeze my trained model in correct format for model inferencing\n",
    "- Develop a Jupyter Notebook to perform inference on the frozen model using unseen test images\n",
    "- Discuss my results.\n",
    "\n",
    "### Prerequisites\n",
    "This notebook runs locally on the environment *tf-gpu*.\n",
    "- Environment Setup (see Part 0)\n",
    "- Preprocessing (see Part 1)\n",
    "- Training (see Part 2)\n",
    "- Run the necessary evaluation scripts (see Part 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a13b846-f597-4ef3-a11c-a87913e96351",
   "metadata": {},
   "source": [
    "## 1. Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb3cd42c-70f0-4302-8fc2-5d11fed5b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d3796a-cc91-4ebe-913b-df561cd6d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Model training directory and config pipeline\n",
    "model_dir = os.path.join(current_dir, 'training')\n",
    "pipeline_config_path = 'ssd_config.config'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63b3465-4546-404c-9190-0f751ba09806",
   "metadata": {},
   "source": [
    "## 2. TensorBoard \n",
    "### 2.1. Monitor region proposal losses, evaluation metrics\n",
    "Here ```logdir``` points to the training directory, by launching the next cell, different loss graphs for region proposal network will be imported by TensorBoard from ```training/train``` folder, whereas evaluation metrics for the given session will be imported from the ```training/eval``` folder.\n",
    "\n",
    "The losses for the Region Proposal Network:\n",
    "\n",
    "- ```Loss/RPNLoss/localization_loss```: Localization Loss or the Loss of the Bounding Box regressor for the RPN\n",
    "\n",
    "- ```Loss/RPNLoss/objectness_loss```: Loss of the Classifier that classifies if a bounding box is an object of interest or background\n",
    "\n",
    "The losses for the Final Classifier:\n",
    "\n",
    "- ```Loss/BoxClassifierLoss/classification_loss```: Loss for the classification of detected objects into various classes: Cat, Dog, Airplane etc\n",
    "\n",
    "- ```BoxClassifierLoss/localization_loss```: Localization Loss or the Loss of the Bounding Box regressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c32dd5d-575f-4364-8bd1-79fe5ac5bab9",
   "metadata": {},
   "source": [
    "### Display the train and evaluation metrics for the given session \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbae6254-c51b-4c1d-89e8-2bfd56be540c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-03 02:05:48.026632: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-03 02:05:49.433084: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2023-01-03 02:05:49.433297: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2023-01-03 02:05:49.433323: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-01-03 02:05:51.186921: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2023-01-03 02:05:51.187074: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: CMPR01\n",
      "2023-01-03 02:05:51.187094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: CMPR01\n",
      "2023-01-03 02:05:51.187325: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.161.3\n",
      "2023-01-03 02:05:51.187385: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.91.3\n",
      "2023-01-03 02:05:51.187407: E tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 460.91.3 does not match DSO version 470.161.3 -- cannot find working devices in this configuration\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.11.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir $current_dir'/training/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bdc29b-be80-4080-8bf1-9abdabf2345c",
   "metadata": {},
   "source": [
    "## 3. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73404608-f3d5-4843-bf84-224741185833",
   "metadata": {},
   "source": [
    "### Training vs Validation losses\n",
    "The training loss indicates how well the model is fitting the training data, while the validation loss indicates how well the model fits new data.\n",
    "- The training total loss was ```train_total_loss = 0.1784```, whereas the validation total loss was ```val_total_loss = 0.2659``` at the last step of training. \n",
    "- Both losses seem to converge down towards lower error levels, which is a sign of a good fit.\n",
    "### Precision Metrics\n",
    "- Our mean average Precision scores at 0.5 and 0.75 levels of IoU were ```mAP@.5 = 0.8711``` and ```mAP@.75 = 0.6416``` respectively, which are above mAP scores of the original Faster R-CNN ResNet101 V1 640x640 (trained on MS COCO Dataset). Our model improved its precision for object detection on our custom database thanks to transfer learning.\n",
    "- Our average Recall (sensitivity) score was ```AR = 0.6083```.\n",
    "\n",
    "Idealy the better mAP and AR the better our model's performance.\n",
    "\n",
    "In summary, it looks like the training and validation total losses were both decreasing over the course of training, which is a good sign that the model is learning. The mean average precision (mAP) scores indicate that the model was able to accurately detect objects in the images with a high degree of precision, and these scores are better than those of a similar model trained on a different dataset (the MS COCO dataset). The average recall score (AR) indicates that the model was able to correctly identify a relatively high proportion of the objects in the images. Overall, it seems that the object detection model was able to learn effectively and achieve good performance on the custom dataset.\n",
    "\n",
    "### Justification for the number of epochs used for training your object detection model\n",
    "\n",
    "```num_epochs``` : A number of epochs of ```1``` means that the model will only make one pass through the entire training dataset. Since we'd like to quickly test the performance of the model on a small training data. However, for most real-world datasets, it is generally not sufficient to train a model to good performance, as the model will not have the opportunity to learn from the entire dataset.\n",
    "\n",
    "It is generally not recommended to train an object detection model using only one epoch, especially if we are using transfer learning with a relatively small dataset of 4000 images. One epoch is typically not sufficient to effectively learn from the data and can lead to poor model performance.\n",
    "\n",
    "Increasing the number of epochs (num_epochs) during training can help improve the performance of an object detection model in a few different ways:\n",
    "\n",
    "- **Increased model convergence**: by allowing the model to see the training data more times, which can help it learn more effectively and converge on a better solution.\n",
    "\n",
    "- **Improved generalisation**: A model that has been trained for more epochs may be better able to generalize to new, unseen data. This is because the model has been exposed to more diverse examples during training and has had more opportunities to learn about the underlying patterns in the data.\n",
    "\n",
    "- **More time for optimisation**: Training for more epochs gives the model more time to adjust its weights and biases through the optimization process. This can lead to improved model performance, especially if the learning rate is set appropriately.\n",
    "\n",
    "Nevertheless, it is important to keep in mind that increasing the number of epochs also increases the training time and can lead to overfitting if the model is trained for too many epochs. Overfitting occurs when a model becomes *too specialized to the training data and performs poorly on new, unseen data*.\n",
    "\n",
    "Note: It was not possible to increase the batch size due to memory limitations. \n",
    "\n",
    "#### **Comparison with Roboflow Cloud-based experiment (using the same model and dataset)**\n",
    "\n",
    "- Using almost the same augmentation steps and the same hyperparameters (except num_epochs, and the batch_size); ```40 epochs``` were needed to converge, the model achieved ```90.1% mAP``` ```88.4% precision``` and ```82.8% recall``` with an average class ```precision``` of ```90%``` on the validation dataset.\n",
    "\n",
    "- We can conclude that increasing the number of epochs and the batch size would lead to better precision and faster training.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/roboflow-platform-cache/RjBpFWbVLQdI2NaOrqg24Eooatr2/qYHiTyjFVuJ6MWIK56Sh/4/results.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ebbd6e-3da3-4881-83dc-06f2cb9ddc84",
   "metadata": {},
   "source": [
    "### Next\n",
    "\n",
    "- Freeze the trained model in correct format for model inferencing\n",
    "- Develop a Jupyter Notebook to perform inference on the frozen model using unseen test images\n",
    "- Discuss my results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlowGPU",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
